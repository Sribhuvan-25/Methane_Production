{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Excel file format cannot be determined, you must specify an engine manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/df.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df_transposed \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      7\u001b[0m df_transposed\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df_transposed\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/pandas/io/excel/_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/pandas/io/excel/_base.py:1500\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1497\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1498\u001b[0m     )\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1503\u001b[0m         )\n\u001b[1;32m   1505\u001b[0m engine \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_option(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.excel.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.reader\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('Data/df.csv', sheet_name=1, header=None, skiprows=1, )\n",
    "\n",
    "df_transposed = df.T\n",
    "\n",
    "df_transposed.columns = df_transposed.iloc[1]\n",
    "df_final = df_transposed.drop([0, 1]).reset_index(drop=True)\n",
    "\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, excluded_columns, categorical_columns):\n",
    "    # One-hot encode the specified categorical columns\n",
    "    print(f\"One-hot encoding categorical columns: {categorical_columns}\")\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "    \n",
    "    # Prepare the feature table by excluding certain columns\n",
    "    feature_columns = [col for col in df.columns if col not in excluded_columns]\n",
    "    features = df[feature_columns].copy()\n",
    "    features.index = df['sample-id']\n",
    "    features.columns = features.columns.str.strip()\n",
    "    features.index = features.index.str.strip()\n",
    "\n",
    "    # Check for duplicate sample IDs\n",
    "    if features.index.duplicated().any():\n",
    "        dup_samples = features.index[features.index.duplicated()]\n",
    "        print(\"Duplicate sample IDs found:\")\n",
    "        print(dup_samples)\n",
    "        raise ValueError(\"Duplicate sample IDs exist. Make sure each sample-id is unique.\")\n",
    "    \n",
    "    # Check for duplicate feature names\n",
    "    if features.columns.duplicated().any():\n",
    "        dup_feats = features.columns[features.columns.duplicated()]\n",
    "        print(\"Duplicate feature IDs found:\")\n",
    "        print(dup_feats)\n",
    "        raise ValueError(\"Duplicate feature IDs exist. Make sure each feature name is unique.\")\n",
    "    \n",
    "    print(\"No duplicate observation IDs found.\")\n",
    "    return features\n",
    "\n",
    "def load_cleaned_data(filepath):\n",
    "    # Load the preprocessed data\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Loaded data from {filepath} with shape {df.shape}\")\n",
    "    \n",
    "    # Rename the first column to 'sample-id' if it isn't already named\n",
    "    if df.columns[0] != 'sample-id':\n",
    "        df.rename(columns={df.columns[0]: 'sample-id'}, inplace=True)\n",
    "        print(\"Renamed the first column to 'sample-id'.\")\n",
    "\n",
    "    # Ensure 'sample-id' values are strings\n",
    "    df['sample-id'] = df['sample-id'].astype(str)\n",
    "\n",
    "    # Remove rows with 'x' values\n",
    "    df = df[~df.isin(['x']).any(axis=1)]\n",
    "    return df\n",
    "\n",
    "filepath_absolute = 'Data/df.csv' # Absolute Abundance\n",
    "df = load_cleaned_data(filepath_absolute)\n",
    "prepare_features(df, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
