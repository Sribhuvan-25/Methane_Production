{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_excel_data(file_path: str, sheet_index: int, skip_rows: int, categorical_columns: list, output_csv: str) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_index, header=None, skiprows=skip_rows)\n",
    "\n",
    "    feature_vector = df.iloc[0:1086, :]\n",
    "    additional_features = df.iloc[1087:1099, :]\n",
    "\n",
    "    full_data = pd.concat([feature_vector.T, additional_features.T], axis=1)\n",
    "    df = full_data.drop(0, axis=0)\n",
    "    df.columns = df.iloc[0]  \n",
    "    df = df[1:].reset_index(drop=True)\n",
    "    df = df[~df.isin(['x']).any(axis=1)]\n",
    "\n",
    "    df = pd.get_dummies(df, columns=categorical_columns).astype(int)\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess_excel_data(\n",
    "    file_path='Data/Data.xlsx',\n",
    "    sheet_index=0,\n",
    "    skip_rows=1,\n",
    "    categorical_columns=['Digester', 'Source', 'Type', 'Waste', 'Biomass'],\n",
    "    output_csv='output.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to Output_Files/unique_digester_samples.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_unique_digester_samples(df: pd.DataFrame, digester_prefix: str, sample_count: int = 20, output_dir: str = \"Output_Files\") -> pd.DataFrame:\n",
    " \n",
    "    digester_columns = [col for col in df.columns if col.startswith(digester_prefix)]\n",
    "    \n",
    "    if not digester_columns:\n",
    "        raise ValueError(\"No one-hot encoded 'Digester' columns found. Check your categorical column names.\")\n",
    "\n",
    "    selected_samples = []\n",
    "\n",
    "    for digester in digester_columns:\n",
    "        digester_group = df[df[digester] == 1]\n",
    "\n",
    "        if not digester_group.empty:\n",
    "            selected_samples.append(digester_group.sample(n=1, random_state=42))  # Ensure reproducibility\n",
    "\n",
    "        if len(selected_samples) == sample_count:\n",
    "            break\n",
    "\n",
    "    unique_digester_samples_df = pd.concat(selected_samples).reset_index(drop=True)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    output_file = os.path.join(output_dir, \"unique_digester_samples.csv\")\n",
    "    unique_digester_samples_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Saved output to {output_file}\")\n",
    "\n",
    "    return unique_digester_samples_df\n",
    "\n",
    "\n",
    "output_directory = \"Output_Files\"\n",
    "\n",
    "unique_samples_df = get_unique_digester_samples(df, digester_prefix='Digester_', sample_count=20, output_dir=output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Biomass_Files/Biomass_F.csv\n",
      "Saved Biomass_Files/Biomass_G.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_and_save_by_biomass(df: pd.DataFrame, biomass_prefix: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Splits the dataset into separate DataFrames based on Biomass type and saves them as CSV files.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The processed DataFrame with one-hot encoded Biomass categories.\n",
    "        biomass_prefix (str): The prefix used for one-hot encoded Biomass columns.\n",
    "        output_dir (str): Directory where the CSV files should be saved.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are Biomass categories, and values are corresponding DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    biomass_columns = [col for col in df.columns if col.startswith(biomass_prefix)]\n",
    "    \n",
    "    if not biomass_columns:\n",
    "        raise ValueError(\"No one-hot encoded 'Biomass' columns found. Check your categorical column names.\")\n",
    "\n",
    "    biomass_dfs = {}\n",
    "\n",
    "    for biomass in biomass_columns:\n",
    "        biomass_df = df[df[biomass] == 1].reset_index(drop=True)\n",
    "\n",
    "        file_path = f\"{output_dir}/{biomass}.csv\"\n",
    "        biomass_df.to_csv(file_path, index=False)\n",
    "\n",
    "        biomass_dfs[biomass] = biomass_df\n",
    "\n",
    "        print(f\"Saved {file_path}\")\n",
    "\n",
    "    return biomass_dfs\n",
    "\n",
    "\n",
    "output_directory = \"Biomass_Files\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "biomass_dataframes = split_and_save_by_biomass(df, biomass_prefix='Biomass_', output_dir=output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
